{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from util import getData\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = getData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer, MultiLabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Dense\n",
    "from keras.layers.core import Activation\n",
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = X_train.shape[0]\n",
    "D = X_train.shape[1]\n",
    "M1 = 2000\n",
    "M2 = 1000\n",
    "M3 = 500\n",
    "K = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stacked autoencoder実装。(無駄があるので、もう少しいい書き方がありそう)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def autoencoder_each_layer(layer, next_layer, input_val):\n",
    "    \"\"\"\n",
    "    各層のautoencoder計算用メソッド。別のmodelを定義して計算しているが、しなくてもできそう。\n",
    "    SequentialじゃないFunction API使えばできそう。\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(layer)\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(next_layer)\n",
    "    model.add(Activation(\"sigmoid\"))\n",
    "    batch_size = 256\n",
    "    nb_epoch = 50\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=\"adadelta\")\n",
    "    model.fit(input_val, input_val, batch_size=batch_size, nb_epoch=nb_epoch, verbose=1, shuffle=True)\n",
    "    return model.get_weights()[0], model.get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_input_value(model, x):\n",
    "    model.compile(optimizer='adadelta', loss='binary_crossentropy')\n",
    "    return model.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "32633/32633 [==============================] - 44s - loss: 0.6967    \n",
      "Epoch 1/1\n",
      "32633/32633 [==============================] - 21s - loss: -0.3762    \n",
      "Epoch 1/1\n",
      "32633/32633 [==============================] - 7s - loss: -0.7088     \n",
      "Epoch 1/1\n",
      "32633/32633 [==============================] - 1s - loss: 0.4855     \n"
     ]
    }
   ],
   "source": [
    "weights = []\n",
    "dims = [D, M1, M2, M3, K]\n",
    "input_value = X_train\n",
    "stacked_model = Sequential()\n",
    "for i in range(len(dims) - 1):\n",
    "    layer = Dense(dims[i + 1], input_shape=(dims[i + 0],))\n",
    "    next_layer = Dense(dims[i + 0])\n",
    "    w, b = autoencoder_each_layer(layer, next_layer, input_value)\n",
    "    weights.append(w)\n",
    "    weights.append(b)\n",
    "    if i == 0:\n",
    "        stacked_model.add(Dense(dims[i + 1], input_shape=(dims[i + 0],), weights=np.array([w, b])))\n",
    "    else:\n",
    "        stacked_model.add(Dense(dims[i + 1], weights=np.array([w, b])))\n",
    "    input_value = predict_input_value(stacked_model, X_train)\n",
    "    if i == len(dims) - 1:\n",
    "        stacked_model.add(Activation(\"softmax\"))\n",
    "    else:\n",
    "        stacked_model.add(Activation(\"relu\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "nb_epoch = 100\n",
    "stacked_model.compile(loss=\"categorical_crossentropy\", optimizer=\"sgd\", metrics=[\"accuracy\"])\n",
    "stacked_model.fit(X_train, y_train, batch_size=batch_size, nb_epoch=nb_epoch, validation_data=(X_test, y_test),verbose=1, shuffle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
